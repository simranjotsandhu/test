# First install required packages
# pip install pandas transformers torch sqlite3

import pandas as pd
import sqlite3
import re
from transformers import AutoTokenizer, AutoModelForCausalLM

# Step 1: Load CSV data into SQLite
def load_csv_to_sqlite(csv_path, db_name='data.db', table_name='my_table'):
    df = pd.read_csv(csv_path)
    conn = sqlite3.connect(db_name)
    df.to_sql(table_name, conn, if_exists='replace', index=False)
    return conn

# Step 2: Get database schema information
def get_schema(conn, table_name):
    cursor = conn.cursor()
    cursor.execute(f"PRAGMA table_info({table_name});")
    columns = cursor.fetchall()
    
    schema = []
    for col in columns:
        schema.append(f"{col[1]} ({col[2]})")
    return f"Table {table_name} with columns: {', '.join(schema)}"

# Step 3: Initialize the language model
def initialize_model():
    model_name = "NousResearch/Hermes-2-Pro-Llama-3-8B"  # Using similar open model
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    return tokenizer, model

# Step 4: Generate SQL from natural language
def generate_sql(query, schema, tokenizer, model):
    prompt = f"""You are an SQL expert. Given this database schema: {schema}
    Convert this natural language query to SQL: {query}
    Return only the SQL query without explanations in this format:
    ```sql
    SELECT * FROM table
    ```"""
    
    inputs = tokenizer(prompt, return_tensors="pt", max_length=1024, truncation=True)
    outputs = model.generate(**inputs, max_new_tokens=200)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # Extract SQL from response
    sql_match = re.search(r'```sql(.*?)```', response, re.DOTALL)
    return sql_match.group(1).strip() if sql_match else response

# Step 5: Execute SQL query
def execute_query(conn, sql):
    try:
        cursor = conn.cursor()
        cursor.execute(sql)
        results = cursor.fetchall()
        columns = [desc[0] for desc in cursor.description]
        return pd.DataFrame(results, columns=columns)
    except sqlite3.Error as e:
        print(f"SQL Error: {e}")
        return None

# Main workflow
def main():
    # Configuration
    CSV_PATH = 'your_data.csv'
    TABLE_NAME = 'my_table'
    
    # Load data
    conn = load_csv_to_sqlite(CSV_PATH, table_name=TABLE_NAME)
    schema = get_schema(conn, TABLE_NAME)
    
    # Initialize model
    tokenizer, model = initialize_model()
    
    # Query interface
    while True:
        nl_query = input("\nEnter your natural language query (or 'exit' to quit): ")
        if nl_query.lower() == 'exit':
            break
        
        # Generate SQL
        sql_query = generate_sql(nl_query, schema, tokenizer, model)
        print(f"\nGenerated SQL:\n{sql_query}")
        
        # Execute and show results
        result = execute_query(conn, sql_query)
        if result is not None:
            print("\nQuery Results:")
            print(result)

    conn.close()

if __name__ == "__main__":
    main()