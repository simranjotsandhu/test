import pandas as pd
from sqlalchemy import create_engine, text
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# Step 1: Load CSV data into SQL database
def load_csv_to_sql(csv_path, table_name='data'):
    # Read CSV file
    df = pd.read_csv(csv_path)
    
    # Create SQLite in-memory database
    engine = create_engine('sqlite:///:memory:')
    
    # Load data into database
    df.to_sql(table_name, engine, index=False, if_exists='replace')
    return engine

# Step 2: Set up LLM for SQL generation
def setup_llm():
    model_name = "meta-llama/Meta-Llama-3-8B-Instruct"  # Use appropriate model version
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.bfloat16,
        device_map="auto"
    )
    return tokenizer, model

# Step 3: Generate SQL from natural language
def generate_sql(query, schema, tokenizer, model):
    prompt = f"""You are a SQL expert. Given this table schema:
{schema}
Generate a SQL query for: {query}
Return ONLY the SQL code with no explanations or formatting."""
    
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
    outputs = model.generate(**inputs, max_new_tokens=200)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# Step 4: Execute SQL query
def execute_query(engine, sql_query):
    try:
        with engine.connect() as conn:
            result = pd.read_sql(text(sql_query), conn)
        return result
    except Exception as e:
        return f"Error: {str(e)}"

# Main workflow
def main(csv_path):
    # Load data
    engine = load_csv_to_sql(csv_path)
    
    # Get schema information
    with engine.connect() as conn:
        schema = conn.execute(text("SELECT sql FROM sqlite_master WHERE type='table';")).fetchone()[0]
    
    # Setup LLM
    tokenizer, model = setup_llm()
    
    # Interactive queries
    while True:
        try:
            nl_query = input("\nEnter your question (or 'exit' to quit): ")
            if nl_query.lower() == 'exit':
                break
            
            # Generate SQL
            sql_query = generate_sql(nl_query, schema, tokenizer, model)
            print(f"\nGenerated SQL: {sql_query}")
            
            # Execute query
            result = execute_query(engine, sql_query)
            print("\nResult:")
            print(result)
            
        except Exception as e:
            print(f"Error processing query: {str(e)}")

if __name__ == "__main__":
    csv_path = "your_data.csv"  # Replace with your CSV file path
    main(csv_path)