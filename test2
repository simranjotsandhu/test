import pandas as pd
from sqlalchemy import create_engine, text
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# Step 1: Load CSV data into SQL database
def load_csv_to_sql(csv_path, table_name='data'):
    # Read CSV file
    df = pd.read_csv(csv_path)
    
    # Create SQLite in-memory database
    engine = create_engine('sqlite:///:memory:')
    
    # Load data into database
    df.to_sql(table_name, engine, index=False, if_exists='replace')
    return engine

# Step 2: Set up LLM for SQL generation
def setup_llm():
    model_name = "meta-llama/Meta-Llama-3-8B-Instruct"  # Use appropriate model version
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.bfloat16,
        device_map="auto"
    )
    return tokenizer, model

# Step 3: Generate SQL from natural language
def generate_sql(query, schema, tokenizer, model):
    prompt = f"""You are a SQL expert. Given this table schema:
{schema}
Generate a SQL query for: {query}
Return ONLY the SQL code with no explanations or formatting."""
    
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
    outputs = model.generate(**inputs, max_new_tokens=200)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# Step 4: Execute SQL query
def execute_query(engine, sql_query):
    try:
        with engine.connect() as conn:
            result = pd.read_sql(text(sql_query), conn)
        return result
    except Exception as e:
        return f"Error: {str(e)}"

# Main workflow
def main(csv_path):
    # Load data
    engine = load_csv_to_sql(csv_path)
    
    # Get schema information
    with engine.connect() as conn:
        schema = conn.execute(text("SELECT sql FROM sqlite_master WHERE type='table';")).fetchone()[0]
    
    # Setup LLM
    tokenizer, model = setup_llm()
    
    # Interactive queries
    while True:
        try:
            nl_query = input("\nEnter your question (or 'exit' to quit): ")
            if nl_query.lower() == 'exit':
                break
            
            # Generate SQL
            sql_query = generate_sql(nl_query, schema, tokenizer, model)
            print(f"\nGenerated SQL: {sql_query}")
            
            # Execute query
            result = execute_query(engine, sql_query)
            print("\nResult:")
            print(result)
            
        except Exception as e:
            print(f"Error processing query: {str(e)}")

if __name__ == "__main__":
    csv_path = "your_data.csv"  # Replace with your CSV file path
    main(csv_path)




import pandas as pd
from sqlalchemy import create_engine, text

def execute_sql_query(engine, generated_query):
    """
    Executes a SQL query on the database and returns formatted results
    """
    try:
        with engine.connect() as connection:
            # Validate and execute query
            result = connection.execute(text(generated_query))
            
            # Convert to pandas DataFrame for nice formatting
            df = pd.DataFrame(result.fetchall(), columns=result.keys())
            
            return {
                "status": "success",
                "data": df,
                "row_count": len(df)
            }
    except Exception as e:
        return {
            "status": "error",
            "message": str(e),
            "query": generated_query
        }

# Full workflow example
if __name__ == "__main__":
    # 1. Load your CSV data
    csv_path = "sales_data.csv"
    df = pd.read_csv(csv_path)
    
    # Sample data (if you need to create test data):
    # data = {'product': ['A', 'B', 'A'], 'sales': [100, 200, 150]}
    # df = pd.DataFrame(data)
    
    # 2. Create in-memory SQL database
    engine = create_engine('sqlite:///:memory:')
    df.to_sql('sales', engine, index=False, if_exists='replace')
    
    # 3. Generated query (this would come from your LLM in practice)
    generated_query = "SELECT product, SUM(sales) as total_sales FROM sales GROUP BY product"
    
    # 4. Execute and display results
    result = execute_sql_query(engine, generated_query)
    
    if result['status'] == 'success':
        print(f"Query executed successfully. Found {result['row_count']} rows")
        print("\nResults:")
        print(result['data'])
    else:
        print("Error executing query:")
        print(f"Query: {result['query']}")
        print(f"Error: {result['message']}")


import re
from sqlparse import parse, format

def clean_sql_response(raw_response):
    """Extract only SQL code from LLM response"""
    # Remove potential markdown code blocks
    cleaned = re.sub(r'```sql\n?|\n?```', '', raw_response, flags=re.IGNORECASE)
    
    # Find first SQL statement using sqlparse
    statements = parse(cleaned)
    if statements:
        # Format and return the first valid SQL statement
        return format(str(statements[0]), strip_comments=True).strip()
    return None

def validate_sql(query):
    """Basic SQL validation"""
    # Check for forbidden operations
    forbidden = ['insert', 'update', 'delete', 'drop', 'alter', ';']
    if any(op in query.lower() for op in forbidden):
        return False
    return True

# Modified generate_sql function
def generate_sql(query, schema, tokenizer, model):
    prompt = f"""You are a SQL expert. Given this table schema:
{schema}
Generate a SQL query for: {query}
Return ONLY the SQL code with no explanations, formatting, or additional text.
Example response: SELECT * FROM table WHERE condition"""

    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
    outputs = model.generate(**inputs, max_new_tokens=200)
    raw_sql = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # Clean and validate the SQL
    cleaned_sql = clean_sql_response(raw_sql)
    if cleaned_sql and validate_sql(cleaned_sql):
        return cleaned_sql
    raise ValueError(f"Invalid SQL generated: {raw_sql}")

# Updated execution flow
def main(csv_path):
    engine = load_csv_to_sql(csv_path)
    tokenizer, model = setup_llm()
    
    with engine.connect() as conn:
        schema = conn.execute(text("SELECT sql FROM sqlite_master WHERE type='table';")).fetchone()[0]

    while True:
        try:
            nl_query = input("\nEnter question (or 'exit'): ")
            if nl_query.lower() == 'exit':
                break

            sql_query = generate_sql(nl_query, schema, tokenizer, model)
            print(f"\nCleaned SQL: {sql_query}")
            
            result = execute_query(engine, sql_query)
            if isinstance(result, pd.DataFrame):
                print(f"\n{result.to_markdown(index=False)}")
            else:
                print(result)
                
        except Exception as e:
            print(f"Error: {str(e)}")

# Additional requirements
# pip install sqlparse


